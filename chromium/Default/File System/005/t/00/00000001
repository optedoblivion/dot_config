{"cid":"kgf1pi0li","id":"VmlldzozNDczNTI0","type":"runs","name":"w0l3ru2boih","displayName":"OpenAI Whisper: How to Transcribe Your Audio to Text, for Free (with SRTs/VTTs)","description":"In this beginner-friendly article, we’ll provide a gentle introduction to Whisper and demonstrate how to use it to transcribe and caption audio — for free!","updatedAt":"2023-06-30T12:04:09","updatedBy":{"id":"VXNlcjo0NDI1NTE=","username":"rmitson","name":"Robert Mitson","admin":false},"createdAt":"2023-02-03T00:31:39","user":{"id":"VXNlcjo4NzM4Mg==","username":"angelicapan","name":"Angelica Pan","photoUrl":"https://storage.googleapis.com/wandb-production.appspot.com/angelicapan/profile.png?Expires=1711954294&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=Krjqug%2BaX3m3d7Ewp4QGc9DmHYU8F%2BNj8RwwuQ%2FIcU0ZaPHQ5A32ezgITy7NMwhrWcZ3lmg%2FdWYOZjmbn3mgo7fJfuchYpnHIA%2FfhsEGcWK8aMj4rtk38jEagXOIwTXdMcru%2BSFBU6ag%2BBzmY8KTe9jIewnCefFqSFluxYxIm%2Bb8y7dVWc4uM2kMsCRXs1P3ocPVK%2F%2BQHM2cAUIl1rZSYbx0rD8xo59mOE65hkM4E15MDxOhwyiYpIOx43rPU4vD6CgawOBqDXM1sn15HI33%2BXMGwhpdBelQtu%2FE5U9zLzcnu8peXyhmqeGydxBbCvcBgMrXh5q2ggWg4OGPzilwyw%3D%3D","admin":false},"entityName":"","project":{"id":"UHJvamVjdDp2MTpnZW50bGUtaW50cm9zOndhbmRiX2Zj","name":"gentle-intros","entityName":"wandb_fc","readOnly":true},"starCount":3,"starred":false,"locked":false,"previewUrl":"https://storage.googleapis.com/wandb-production.appspot.com/wandb_fc/images/views/3473524/preview.png?md5=d7723de8d06c4f3540b264995c4a4b82","viewCount":51394,"accessTokens":[],"spec":{"version":5,"panelSettings":{"xAxis":"_step","smoothingWeight":0,"smoothingType":"exponential","ignoreOutliers":false,"xAxisActive":false,"smoothingActive":false,"useRunsTableGroupingInPanels":true,"ref":{"type":"panelSettings","viewID":"oiz1vael7","id":"qy704nwnr"}},"blocks":[{"type":"paragraph","children":[{"text":"In this article, we’ll show you how to automatically transcribe audio files "},{"strong":true,"text":"for free"},{"text":", using OpenAI’s Whisper. You’ll learn how to save these transcriptions as a plain text file, as captions with time code data (aka as an SRT or VTT file), and even as a TSV or JSON file."}]},{"type":"callout-block","children":[{"type":"callout-line","children":[{"text":"If you’d like to skip ahead to the code and instructions, click here!"}]}]},{"type":"paragraph","children":[{"text":"We’ll start by answering questions like:"}]},{"type":"list","children":[{"type":"list-item","children":[{"type":"paragraph","children":[{"text":""},{"type":"link","url":"https://wandb.ai/wandb_fc/gentle-intros/reports/How-to-transcribe-your-audio-to-text-for-free-with-SRTs-VTTs---VmlldzozNDczNTI0#what-is-openai’s-whisper?","children":[{"text":"What is Whisper?"}]},{"text":""}]}],"checked":null,"spread":false,"ordered":false},{"type":"list-item","children":[{"type":"paragraph","children":[{"text":""},{"type":"link","url":"https://wandb.ai/wandb_fc/gentle-intros/reports/How-to-transcribe-your-audio-to-text-for-free-with-SRTs-VTTs---VmlldzozNDczNTI0#how-long-does-whisper-take?","children":[{"text":"How long does Whisper take?"}]},{"text":""}]}],"checked":null,"spread":false,"ordered":false},{"type":"list-item","children":[{"type":"paragraph","children":[{"text":""},{"type":"link","children":[{"text":"What are transcriptions/captions?"}],"url":"https://wandb.ai/wandb_fc/gentle-intros/reports/How-to-transcribe-your-audio-to-text-for-free-with-SRTs-VTTs---VmlldzozNDczNTI0#what-are-transcriptions-and-captions?","title":null},{"text":""}]}],"checked":null,"spread":false,"ordered":false},{"type":"list-item","children":[{"type":"paragraph","children":[{"text":""},{"type":"link","children":[{"text":"What is an SRT/VTT file?"}],"url":"https://wandb.ai/wandb_fc/gentle-intros/reports/How-to-transcribe-your-audio-to-text-for-free-with-SRTs-VTTs---VmlldzozNDczNTI0#what-is-an-srt/vtt-file?","title":null},{"text":""}]}],"checked":null,"spread":false,"ordered":false}],"ordered":false,"start":null,"spread":false},{"type":"paragraph","children":[{"text":"Then, we’ll jump into the how-to section of this article and show you how to "},{"type":"link","children":[{"text":"use Whisper to transcribe your own files"}],"url":"https://wandb.ai/wandb_fc/gentle-intros/reports/How-to-transcribe-your-audio-to-text-for-free-with-SRTs-VTTs---VmlldzozNDczNTI0#how-to-run-whisper","title":null},{"text":" and "},{"type":"link","children":[{"text":"save them as caption files"}],"url":"https://wandb.ai/wandb_fc/gentle-intros/reports/How-to-transcribe-your-audio-to-text-for-free-with-SRTs-VTTs---VmlldzozNDczNTI0#saving-a-whisper-transcription-as-an-srt/vtt-file","title":null},{"text":"."}]},{"type":"paragraph","children":[{"text":"We also provide a "},{"type":"link","children":[{"text":"companion Colab"}],"url":"https://colab.research.google.com/drive/1zEydNXx3OvbIf_IwfFkJN34ipwp3rgiQ?usp=sharing","title":null},{"text":" that you can use to immediately get started with audio transcription ⬇️"}]},{"type":"image","url":"https://colab.research.google.com/assets/colab-badge.svg","title":null,"alt":"Open In Colab","children":[{"text":"Click the button above!"}],"href":"https://colab.research.google.com/drive/1zEydNXx3OvbIf_IwfFkJN34ipwp3rgiQ?usp=sharing","width":299,"hasCaption":true},{"type":"paragraph","children":[{"text":"Finally, if you’re interested in exploring Whisper more and comparing how well the different Whisper model sizes transcribe audio, we’ll finish this article with an introduction to a future part 2, “How to Track and Compare Audio Transcriptions with Whisper and Weights & Biases.”"}]},{"type":"paragraph","children":[{"text":"Here's what we'll be covering: "}]},{"type":"heading","children":[{"text":"Table of Contents"}],"level":3},{"type":"table-of-contents","level":2,"children":[{"text":""}],"displayLevel":2},{"type":"heading","children":[{"text":"Background to Whisper"}],"level":1},{"type":"paragraph","children":[{"text":"This section contains helpful, but optional, background information. Click "},{"type":"link","url":"https://wandb.ai/wandb_fc/gentle-intros/reports/How-to-transcribe-your-audio-to-text-for-free-with-SRTs-VTTs---VmlldzozNDczNTI0#how-to-run-whisper","children":[{"text":"here"}]},{"text":" if you'd like to jump straight into running Whisper."}]},{"type":"heading","children":[{"text":"What is OpenAI’s Whisper?"}],"level":2},{"type":"paragraph","children":[{"text":""},{"type":"link","children":[{"text":"Whisper"}],"url":"https://github.com/openai/whisper","title":null},{"text":" is an open source ASR library released by "},{"type":"link","children":[{"text":"OpenAI"}],"url":"https://openai.com/","title":null},{"text":" in "},{"type":"link","children":[{"text":"September 2022"}],"url":"https://openai.com/blog/whisper/","title":null},{"text":". Whisper takes an audio or audiovisual file as input and returns a transcription of the audio as output. This transcription can be saved as a plain text file, or as a subtitle file with time code data. "}]},{"type":"paragraph","children":[{"text":"OpenAI is the AI research company behind the incredibly powerful chatbot "},{"type":"link","children":[{"text":"ChatGPT"}],"url":"https://openai.com/blog/chatgpt/","title":null},{"text":" and the popular text-to-image model "},{"type":"link","children":[{"text":"DALL-E 2"}],"url":"https://openai.com/dall-e-2/","title":null},{"text":". "}]},{"type":"paragraph","children":[{"text":"Exactly "},{"emphasis":true,"text":"how"},{"text":" Whisper creates these transcriptions is a little bit beyond the scope of this article, but in a nutshell: Whisper is a deep learning model trained on 680,000 hours of "},{"text":"multilingual","inlineComment_yji60gzp1":{"refID":"yji60gzp1","threadID":"RGlzY3Vzc2lvblRocmVhZDo1NTIx","commentID":"RGlzY3Vzc2lvbkNvbW1lbnQ6Nzk3MA=="}},{"text":" audio data and their transcriptions. Through the training process, Whisper learns to process audio input and predict the most appropriate corresponding text caption."}]},{"type":"paragraph","children":[{"text":"Whisper comes in five different sizes, with different trade-offs between transcription quality, memory requirements, and relative speed."}]},{"type":"image","children":[{"text":"Whisper's available models and languages ("},{"type":"link","url":"https://github.com/openai/whisper#available-models-and-languages","children":[{"text":"source"}]},{"text":")"}],"url":"https://api.wandb.ai/files/wandb_fc/images/projects/37068502/98948940.png","hasCaption":true},{"type":"heading","children":[{"text":"A Quick Disclaimer"}],"level":2},{"type":"paragraph","children":[{"text":"AI-powered automatic speech recognition (ASR) technology is still improving, and Whisper transcriptions are not perfect. "}]},{"type":"paragraph","children":[{"text":"The transcription might lack some punctuation, incorrectly transcribe some words, or completely miss and not transcribe some words at all. Whisper also does not distinguish between speakers, and does not provide any indication of when or if a speaker changes. If you’re looking to publish Whisper transcriptions — as subtitles to a YouTube video, as part of a blog post, et cetera — you may wish to proofread them beforehand and do some manual corrections."}]},{"type":"paragraph","children":[{"text":"That being said, Whisper transcriptions are remarkably good, and Whisper represents a huge advance in the improvement of audio to text technology. Plus, Whisper is open source, giving the general public completely free (!!!) access to state-of-the-art software."}]},{"type":"paragraph","level":2,"children":[{"emphasis":true,"strong":true,"text":"A note from the author:"},{"emphasis":true,"text":" (February 3, 2023) Whisper is an open source library in active development. If any of the code in this article or the companion Colab no longer works, please leave a comment and let me know!"}]},{"type":"heading","children":[{"text":"A Preview of Whisper"}],"level":2},{"type":"paragraph","children":[{"text":"Here’s an example of running Whisper on the first ~30 seconds of \""},{"type":"link","children":[{"text":"Cristóbal Valenzuela — The Next Generation of Content Creation and AI"}],"url":"https://www.youtube.com/watch?v=wbonGgk-_Gk","title":null},{"text":"\", an interview between Cristóbal Valenzuela (CEO and co-founder of "},{"type":"link","children":[{"text":"Runway"}],"url":"https://runwayml.com/","title":null},{"text":") and Lukas Biewald (CEO and co-founder of "},{"type":"link","children":[{"text":"Weights & Biases"}],"url":"https://wandb.ai/site","title":null},{"text":")."}]},{"type":"video","url":"https://www.youtube.com/embed/wbonGgk-_Gk","children":[{"text":""}]},{"type":"paragraph","children":[{"text":""}]},{"type":"block-quote","children":[{"type":"paragraph","children":[{"text":"I think a big mistake of research, specifically in the way of computational creativity, is the idea that you can automate it entirely. So you see one-click ops solutions to do X, Y, or Z. I think that's the bigger picture of how most creative work should actually work. Or that probably means that you've never actually worked with an agency where the client was asking you to change things every single hour, make it bigger, make it smaller, right? You're listening to Gradient Dissent, a show about machine learning in the real world. And I'm your host, Lukas Biewald."},{"type":"link","children":[{"text":""}],"url":"https://www.youtube.com/watch?v=wbonGgk-_Gk","title":null},{"text":""}]}]},{"type":"heading","children":[{"text":"How Long Does Whisper Take?"}],"level":2},{"type":"paragraph","level":2,"children":[{"text":"It depends on the length of your file and what type of hardware you have access to!"}]},{"type":"paragraph","level":2,"children":[{"text":"When we ran the "},{"text":"medium.en","inlineCode":true},{"text":" Whisper model on the 40-minute \""},{"type":"link","url":"https://www.youtube.com/watch?v=wbonGgk-_Gk","children":[{"text":"Cristóbal Valenzuela — The Next Generation of Content Creation and AI"}]},{"text":"\" interview, it took:"}]},{"type":"list","children":[{"type":"list-item","level":2,"children":[{"type":"paragraph","children":[{"text":"About 6 minutes on GPU"}]}]},{"type":"list-item","level":2,"children":[{"type":"paragraph","children":[{"text":"About 1.5 hours on CPU"}]}]}]},{"type":"heading","children":[{"text":"What Types of File Formats Can Whisper Process?"}],"level":2},{"type":"paragraph","children":[{"text":"Whisper uses "},{"type":"link","children":[{"text":"ffmpeg"}],"url":"https://ffmpeg.org/","title":null},{"text":" to load audio  — theoretically any audio or audiovisual format that "},{"type":"link","children":[{"text":"ffmpeg supports"}],"url":"https://ffmpeg.org/ffmpeg-formats.html","title":null},{"text":" should be okay, although we haven’t tested different formats extensively. MP3, FLAC, and WAV files definitely work — as do audiovisual MP4 files."}]},{"type":"heading","children":[{"text":"What Are Transcriptions and Captions?"}],"level":2},{"type":"paragraph","children":[{"text":"Audio transcription is the process of converting the speech in an audio or audiovisual file into a written format. The resulting text document is a transcription. Captions are like transcriptions, but with time code data that synchronizes the text to the corresponding speech in the original file."}]},{"type":"paragraph","children":[{"text":"Transcriptions and captions are valuable for many reasons, including:"}]},{"type":"list","children":[{"type":"list-item","children":[{"type":"paragraph","children":[{"text":"Audio content becomes accessible to people who are deaf or hard of hearing"}]}],"checked":null,"spread":false,"ordered":false},{"type":"list-item","children":[{"type":"paragraph","children":[{"text":"Audio content that is difficult to understand (poor recording quality, background noise, speaker pronunciation, etc.) becomes more accessible"}]}],"checked":null,"spread":false,"ordered":false},{"type":"list-item","children":[{"type":"paragraph","children":[{"text":"Written content is generally easier and faster to skim or understand than audio content"}]}],"checked":null,"spread":false,"ordered":false},{"type":"list-item","children":[{"type":"paragraph","children":[{"text":"Written content is easier to search for than audio content, providing search engine optimization benefits"}]}],"checked":null,"spread":false,"ordered":false}],"ordered":false,"start":null,"spread":false},{"type":"paragraph","children":[{"text":"Manually creating transcripts can be quite tedious, and captions even more so. Transcribing requires listening to the audio and typing out the corresponding speech. Captioning takes it a step further, and requires indicating which timestamps (down to the millisecond) in the original file correspond to which lines of transcribed text."}]},{"type":"paragraph","children":[{"text":"These slices of audio range from 2-4 seconds, meaning that even a few minutes of audio/video can result in very, very long caption files. "}]},{"type":"paragraph","children":[{"text":"Here’s an example of a plain text transcript vs the VTT captions for the same ~30 seconds "},{"type":"link","children":[{"text":"transcribed above"}],"url":"https://www.notion.so/How-to-transcribe-your-audio-to-text-for-free-with-SRTs-VTTs-f0bfe2cd693a4f369649bf31c046998c","title":null},{"text":"."}]},{"type":"panel-grid","children":[{"text":""}],"metadata":{"openViz":true,"name":"unused-name","ref":{"type":"section","viewID":"e0spf1nk8","id":"nftx90rk0"},"runSets":[{"runFeed":{"version":2,"columnVisible":{"run:name":false},"columnPinned":{},"columnWidths":{},"columnOrder":[],"pageSize":10,"onlyShowSelected":false},"enabled":true,"name":"Run set","search":{"query":""},"id":"84l29l0tf","ref":{"type":"runSet","viewID":"e0spf1nk8","id":"6ooghk3yp"},"filters":{"op":"OR","filters":[{"op":"AND","filters":[]}],"ref":{"type":"filters","viewID":"e0spf1nk8","id":"s6g4ijg5c"}},"grouping":[],"sort":{"keys":[{"key":{"section":"run","name":"createdAt"},"ascending":false}],"ref":{"type":"sort","viewID":"e0spf1nk8","id":"bmig9qj58"}},"selections":{"root":1,"bounds":[],"tree":[]},"expandedRowAddresses":[]}],"panels":{"views":{"0":{"name":"Panels","defaults":[],"config":[],"panelRefs":[]}},"tabs":["0"],"ref":{"type":"panels","viewID":"e0spf1nk8","id":"e8zaauv2i"}},"panelBankConfig":{"state":0,"settings":{"autoOrganizePrefix":2,"showEmptySections":false,"sortAlphabetically":false,"toggleRunAggregation":true},"ref":{"type":"panel-bank-config","viewID":"e0spf1nk8","id":"vl29236wy"},"sections":[{"name":"Hidden Panels","isOpen":false,"type":"flow","flowConfig":{"snapToColumns":true,"columnsPerPage":3,"rowsPerPage":2,"gutterWidth":16,"boxWidth":460,"boxHeight":300},"sorted":0,"localPanelSettings":{"xAxis":"_step","smoothingWeight":0,"smoothingType":"exponential","ignoreOutliers":false,"xAxisActive":false,"smoothingActive":false,"useRunsTableGroupingInPanels":true,"ref":{"type":"panelSettings","viewID":"e0spf1nk8","id":"77c7ktynf"}},"localPanelSettingsRef":{"type":"panelSettings","viewID":"e0spf1nk8","id":"77c7ktynf"},"ref":{"type":"panel-bank-section-config","viewID":"e0spf1nk8","id":"8dmi6h7tw"},"panels":[],"panelRefs":[]}]},"panelBankSectionConfig":{"name":"Report Panels","isOpen":true,"type":"grid","flowConfig":{"snapToColumns":true,"columnsPerPage":3,"rowsPerPage":2,"gutterWidth":16,"boxWidth":460,"boxHeight":300},"sorted":0,"localPanelSettings":{"xAxis":"_step","smoothingWeight":0,"smoothingType":"exponential","ignoreOutliers":false,"xAxisActive":false,"smoothingActive":false,"useRunsTableGroupingInPanels":true,"ref":{"type":"panelSettings","viewID":"e0spf1nk8","id":"bfw7ma227"}},"localPanelSettingsRef":{"type":"panelSettings","viewID":"e0spf1nk8","id":"bfw7ma227"},"ref":{"type":"panel-bank-section-config","viewID":"e0spf1nk8","id":"tlysogrjy"},"panels":[{"__id__":"jm3236vbi","viewType":"Markdown Panel","config":{"value":"00:00.000 --> 00:07.520\n\nI think a big mistake of research, specifically in the way of computational creativity, is\n\n00:07.520 --> 00:09.880\n\nthe idea that you can automate it entirely.\n\n00:09.880 --> 00:13.200\n\nSo you see one-click ops solutions to do X, Y, or Z.\n\n00:13.200 --> 00:18.900\n\nI think that's the bigger picture of how most creative work should actually work.\n\n00:18.900 --> 00:21.820\n\nOr that probably means that you've never actually worked with an agency where the client was\n\n00:21.820 --> 00:26.940\n\nasking you to change things every single hour, make it bigger, make it smaller, right?\n\n00:26.940 --> 00:31.320\n\nYou're listening to Gradient Dissent, a show about machine learning in the real world.\n\n00:31.320 --> 00:34.200\n\nAnd I'm your host, Lukas Biewald."},"ref":{"type":"panel","viewID":"e0spf1nk8","id":"r19i9omzy"},"layout":{"x":12,"y":0,"w":8,"h":10}},{"__id__":"b16e46a3q","viewType":"Markdown Panel","config":{"value":"I think a big mistake of research, specifically in the way of computational creativity, is the idea that you can automate it entirely. So you see one-click ops solutions to do X, Y, or Z. I think that's the bigger picture of how most creative work should actually work. Or that probably means that you've never actually worked with an agency where the client was asking you to change things every single hour, make it bigger, make it smaller, right? You're listening to Gradient Dissent, a show about machine learning in the real world. And I'm your host, Lukas Biewald."},"ref":{"type":"panel","viewID":"e0spf1nk8","id":"4v3njw4fw"},"layout":{"x":4,"y":0,"w":8,"h":10}}],"panelRefs":[{"type":"panel","viewID":"e0spf1nk8","id":"r19i9omzy"},{"type":"panel","viewID":"e0spf1nk8","id":"4v3njw4fw"}]},"customRunColors":{"ref":{"type":"run-colors","viewID":"e0spf1nk8","id":"jeq9k6ifo"}}}},{"type":"paragraph","children":[{"text":"There are many paid transcription/captioning services that will do the hard work for you, with prices ranging from "},{"type":"link","children":[{"text":"$0.25"}],"url":"https://www.rev.com/services/auto-audio-transcription","title":null},{"text":" (AI-generated, transcription only) to "},{"type":"link","children":[{"text":"$1.50"}],"url":"https://www.rev.com/services/audio-transcription","title":null},{"text":" (human-created) per minute of audio."}]},{"type":"paragraph","children":[{"text":"For the Gradient Dissent episode above, that means you would save between $10 and $60 by using Whisper, disregarding hardware cost."}]},{"type":"paragraph","children":[{"text":"In this article, we’ll show you how to use Whisper, the popular machine learning ASR model, to automatically generate high quality transcripts "},{"emphasis":true,"text":"and"},{"text":" captions on your own. They won’t be perfect but they’ll be pretty close — and more importantly, they’ll be free."}]},{"type":"heading","children":[{"text":"What Is An SRT/VTT file?"}],"level":2},{"type":"paragraph","children":[{"text":"There are "},{"type":"link","children":[{"text":"many different caption file formats"}],"url":"https://support.google.com/youtube/answer/2734698?hl=en","title":null},{"text":"; SRT and VTT are arguably two of the most common ones. In a nutshell, VTT files are more complex than SRT files, because they offer more formatting options and store metadata."}]},{"type":"paragraph","children":[{"text":"In the context of this article, SRT and VTT files are functionally equivalent. Whisper can easily export captions in both formats, and although VTTs are "},{"emphasis":true,"text":"capable"},{"text":" of storing more information (formatting options, metadata) than SRTs, Whisper does not not include any additional information when exporting captions as a VTT file."}]},{"type":"paragraph","children":[{"text":"Read these posts for more information on "},{"type":"link","children":[{"text":"different caption formats"}],"url":"https://www.3playmedia.com/blog/guide-caption-description-formats-video-player/","title":null},{"text":", about the "},{"type":"link","children":[{"text":"differences between SRT and VTT files"}],"url":"https://jbilocalization.com/the-difference-between-srt-and-webvtt-in-captioning-subtitling/","title":null},{"text":", and "},{"type":"link","children":[{"text":"when you should use which format"}],"url":"https://www.getsubly.com/post/srt-vtt","title":null},{"text":"."}]},{"type":"heading","children":[{"text":"How to Run Whisper"}],"level":1},{"type":"paragraph","children":[{"text":"Whisper is available as a command line tool and as an importable Python library. In this article, we’ll focus on the Whisper Python library."}]},{"type":"heading","children":[{"text":"Transcribing Audio With Whisper"}],"level":2},{"type":"paragraph","children":[{"text":"Transcribing audio with Whisper is pretty straightforward — there are really only two main steps:"}]},{"type":"list","children":[{"type":"list-item","children":[{"type":"paragraph","children":[{"text":"Load the desired Whisper model with "},{"inlineCode":true,"text":"whisper.load_model()"}]}],"checked":null,"spread":false,"ordered":true},{"type":"list-item","children":[{"type":"paragraph","children":[{"text":"Transcribe the desired audio file with the "},{"inlineCode":true,"text":"transcribe()"},{"text":" method"}]}],"checked":null,"spread":false,"ordered":true}],"ordered":true,"start":1,"spread":false},{"type":"paragraph","children":[{"text":"Here’s a minimal example, from the "},{"type":"link","children":[{"text":"Whisper repo on GitHub"}],"url":"https://github.com/openai/whisper#python-usage","title":null},{"text":"."}]},{"type":"code-block","language":"python","children":[{"type":"code-line","language":"python","children":[{"text":"import whisper"}]},{"type":"code-line","language":"python","children":[{"text":""}]},{"type":"code-line","language":"python","children":[{"text":"model = whisper.load_model(\"base\")"}]},{"type":"code-line","language":"python","children":[{"text":"result = model.transcribe(\"audio.mp3\")"}]}]},{"type":"paragraph","children":[{"text":"Whisper’s "},{"inlineCode":true,"text":"transcribe()"},{"text":" method returns a dictionary with three key-value pairs:"}]},{"type":"list","children":[{"type":"list-item","children":[{"type":"paragraph","children":[{"inlineCode":true,"text":"“text”"},{"text":": The transcription (type: str)"}]}],"checked":null,"spread":false,"ordered":false},{"type":"list-item","children":[{"type":"paragraph","children":[{"inlineCode":true,"text":"“segments”"},{"text":": Segment-level details, including a segmented transcription and time code data (type: list of dictionaries)"}]}],"checked":null,"spread":false,"ordered":false},{"type":"list-item","children":[{"type":"paragraph","children":[{"inlineCode":true,"text":"“language”"},{"text":": The spoken language (type: str)"}]}],"checked":null,"spread":false,"ordered":false}],"ordered":false,"start":null,"spread":false},{"type":"heading","children":[{"text":"Saving a Whisper Transcription As a Plain Text File"}],"level":2},{"type":"paragraph","children":[{"text":"To save the transcription as a text file, open a new text file and write the value of the "},{"inlineCode":true,"text":"\"text\""},{"text":" key into that file."}]},{"type":"code-block","language":"python","children":[{"type":"code-line","language":"python","children":[{"text":"import whisper"}]},{"type":"code-line","language":"python","children":[{"text":""}]},{"type":"code-line","language":"python","children":[{"text":"model = whisper.load_model(\"base\")"}]},{"type":"code-line","language":"python","children":[{"text":"audio = \"audio.mp3\""}]},{"type":"code-line","language":"python","children":[{"text":"result = model.transcribe(audio)"}]},{"type":"code-line","language":"python","children":[{"text":""}]},{"type":"code-line","language":"python","children":[{"text":"with open(\"transcription.txt\", \"w\", encoding=\"utf-8\") as txt:"}]},{"type":"code-line","language":"python","children":[{"text":"    txt.write(result[\"text\"])"}]}]},{"type":"paragraph","children":[{"text":"Or, you can use the built-in "},{"type":"link","url":"https://github.com/openai/whisper/blob/main/whisper/utils.py#L144","children":[{"text":"get_writer()","inlineCode":true}]},{"text":" function, which ultimately calls "},{"type":"link","url":"https://github.com/openai/whisper/blob/main/whisper/utils.py#L80","children":[{"text":"WriteTXT.write_result()","inlineCode":true}]},{"text":"."}]},{"type":"paragraph","children":[{"text":"This method creates a plain text file with hard line breaks, where each line corresponds to a “segment” of the transcription. Here, “segment” refers to how Whisper divides the transcription into smaller, caption-sized chunks."}]},{"type":"paragraph","children":[{"text":"In contrast, using the simple "},{"text":"write()","inlineCode":true},{"text":" method creates a text file with no line breaks whatsoever."}]},{"type":"code-block","language":"python","children":[{"type":"code-line","language":"python","children":[{"text":"import whisper"}]},{"type":"code-line","language":"python","children":[{"text":"from whisper.utils import get_writer"}]},{"type":"code-line","language":"python","children":[{"text":""}]},{"type":"code-line","language":"python","children":[{"text":"model = whisper.load_model(\"base\")"}]},{"type":"code-line","language":"python","children":[{"text":"audio = \"audio.mp3\""}]},{"type":"code-line","language":"python","children":[{"text":"result = model.transcribe(audio)"}]},{"type":"code-line","language":"python","children":[{"text":"output_directory = \"./\""}]},{"type":"code-line","language":"python","children":[{"text":""}]},{"type":"code-line","language":"python","children":[{"text":"# Save as a TXT file without any line breaks"}]},{"type":"code-line","language":"python","children":[{"text":"with open(\"transcription.txt\", \"w\", encoding=\"utf-8\") as txt:"}]},{"type":"code-line","language":"python","children":[{"text":"    txt.write(result[\"text\"])"}]},{"type":"code-line","language":"python","children":[{"text":""}]},{"type":"code-line","language":"python","children":[{"text":"# Save as a TXT file with hard line breaks"}]},{"type":"code-line","language":"python","children":[{"text":"txt_writer = get_writer(\"txt\", output_directory)"}]},{"type":"code-line","language":"python","children":[{"text":"txt_writer(result, audio)"}]}]},{"type":"paragraph","children":[{"text":"Here’s the plain text transcript for the ~30 seconds "},{"type":"link","children":[{"text":"transcribed above"}],"url":"https://www.notion.so/How-to-transcribe-your-audio-to-text-for-free-with-SRTs-VTTs-f0bfe2cd693a4f369649bf31c046998c","title":null},{"text":", as a text file without any line breaks and with hard line breaks (empty new lines added for clarity)."}]},{"type":"panel-grid","children":[{"text":""}],"metadata":{"openViz":true,"name":"unused-name","ref":{"type":"section","viewID":"pyg9kor52","id":"bctntq1gu"},"runSets":[{"runFeed":{"version":2,"columnVisible":{"run:name":false},"columnPinned":{},"columnWidths":{},"columnOrder":[],"pageSize":10,"onlyShowSelected":false},"enabled":true,"name":"Run set","search":{"query":""},"id":"84l29l0tf","ref":{"type":"runSet","viewID":"pyg9kor52","id":"2nfzrki8n"},"filters":{"op":"OR","filters":[{"op":"AND","filters":[]}],"ref":{"type":"filters","viewID":"pyg9kor52","id":"zop3ihkoh"}},"grouping":[],"sort":{"keys":[{"key":{"section":"run","name":"createdAt"},"ascending":false}],"ref":{"type":"sort","viewID":"pyg9kor52","id":"9rc6rd985"}},"selections":{"root":1,"bounds":[],"tree":[]},"expandedRowAddresses":[]}],"panels":{"views":{"0":{"name":"Panels","defaults":[],"config":[],"panelRefs":[]}},"tabs":["0"],"ref":{"type":"panels","viewID":"pyg9kor52","id":"fc8o3xt5z"}},"panelBankConfig":{"state":0,"settings":{"autoOrganizePrefix":2,"showEmptySections":false,"sortAlphabetically":false,"toggleRunAggregation":true},"ref":{"type":"panel-bank-config","viewID":"pyg9kor52","id":"sl4cqshh9"},"sections":[{"name":"Hidden Panels","isOpen":false,"type":"flow","flowConfig":{"snapToColumns":true,"columnsPerPage":3,"rowsPerPage":2,"gutterWidth":16,"boxWidth":460,"boxHeight":300},"sorted":0,"localPanelSettings":{"xAxis":"_step","smoothingWeight":0,"smoothingType":"exponential","ignoreOutliers":false,"xAxisActive":false,"smoothingActive":false,"useRunsTableGroupingInPanels":true,"ref":{"type":"panelSettings","viewID":"pyg9kor52","id":"tucx5l8yf"}},"localPanelSettingsRef":{"type":"panelSettings","viewID":"pyg9kor52","id":"tucx5l8yf"},"ref":{"type":"panel-bank-section-config","viewID":"pyg9kor52","id":"4rlwkbcvx"},"panels":[],"panelRefs":[]}]},"panelBankSectionConfig":{"name":"Report Panels","isOpen":true,"type":"grid","flowConfig":{"snapToColumns":true,"columnsPerPage":3,"rowsPerPage":2,"gutterWidth":16,"boxWidth":460,"boxHeight":300},"sorted":0,"localPanelSettings":{"xAxis":"_step","smoothingWeight":0,"smoothingType":"exponential","ignoreOutliers":false,"xAxisActive":false,"smoothingActive":false,"useRunsTableGroupingInPanels":true,"ref":{"type":"panelSettings","viewID":"pyg9kor52","id":"wlukh5q8e"}},"localPanelSettingsRef":{"type":"panelSettings","viewID":"pyg9kor52","id":"wlukh5q8e"},"ref":{"type":"panel-bank-section-config","viewID":"pyg9kor52","id":"aa3lv0lui"},"panels":[{"__id__":"jm3236vbi","viewType":"Markdown Panel","config":{"value":"I think a big mistake of research, specifically in the way of computational creativity, is\n\nthe idea that you can automate it entirely.\n\nSo you see one-click ops solutions to do X, Y, or Z.\n\nI think that's the bigger picture of how most creative work should actually work.\n\nOr that probably means that you've never actually worked with an agency where the client was\n\nasking you to change things every single hour, make it bigger, make it smaller, right?\n\nYou're listening to Gradient Dissent, a show about machine learning in the real world.\n\nAnd I'm your host, Lukas Biewald."},"ref":{"type":"panel","viewID":"pyg9kor52","id":"cy3jnh7ob"},"layout":{"x":12,"y":0,"w":8,"h":10}},{"__id__":"b16e46a3q","viewType":"Markdown Panel","config":{"value":"I think a big mistake of research, specifically in the way of computational creativity, is the idea that you can automate it entirely. So you see one-click ops solutions to do X, Y, or Z. I think that's the bigger picture of how most creative work should actually work. Or that probably means that you've never actually worked with an agency where the client was asking you to change things every single hour, make it bigger, make it smaller, right? You're listening to Gradient Dissent, a show about machine learning in the real world. And I'm your host, Lukas Biewald."},"ref":{"type":"panel","viewID":"pyg9kor52","id":"leflkqxfj"},"layout":{"x":4,"y":0,"w":8,"h":10}}],"panelRefs":[{"type":"panel","viewID":"pyg9kor52","id":"cy3jnh7ob"},{"type":"panel","viewID":"pyg9kor52","id":"leflkqxfj"}]},"customRunColors":{"ref":{"type":"run-colors","viewID":"pyg9kor52","id":"7v3cler9x"}}}},{"type":"paragraph","children":[{"text":"In this article and the companion Colab, we’ll use the "},{"inlineCode":true,"text":"write()"},{"text":" method to save a transcription without any line breaks, but ultimately the choice between "},{"inlineCode":true,"text":"write()"},{"text":" and "},{"text":"get_writer()","inlineCode":true},{"text":" just comes down to your individual use case and preference. "}]},{"type":"heading","children":[{"text":"Saving a Whisper Transcription As An SRT/VTT File"}],"level":2},{"type":"paragraph","children":[{"text":"To save the transcription as an SRT/VTT file, use the "},{"text":"get_writer()","inlineCode":true},{"text":" function to call the "},{"type":"link","url":"https://github.com/openai/whisper/blob/main/whisper/utils.py#L102","children":[{"text":"WriteSRT.write_result()","inlineCode":true}]},{"text":" and "},{"type":"link","url":"https://github.com/openai/whisper/blob/main/whisper/utils.py#L88","children":[{"text":"WriteVTT.write_result()","inlineCode":true}]},{"text":" methods, respectively."}]},{"type":"code-block","language":"python","children":[{"type":"code-line","language":"python","children":[{"text":"import whisper"}]},{"type":"code-line","language":"python","children":[{"text":"from whisper.utils import get_writer"}]},{"type":"code-line","language":"python","children":[{"text":""}]},{"type":"code-line","language":"python","children":[{"text":"model = whisper.load_model(\"base\")"}]},{"type":"code-line","language":"python","children":[{"text":"audio = \"audio.mp3\""}]},{"type":"code-line","language":"python","children":[{"text":"result = model.transcribe(audio)"}]},{"type":"code-line","language":"python","children":[{"text":"output_directory = \"./\""}]},{"type":"code-line","language":"python","children":[{"text":""}]},{"type":"code-line","language":"python","children":[{"text":"# Save as an SRT file"}]},{"type":"code-line","language":"python","children":[{"text":"srt_writer = get_writer(\"srt\", output_directory)"}]},{"type":"code-line","language":"python","children":[{"text":"srt_writer(result, audio)"}]},{"type":"code-line","language":"python","children":[{"text":""}]},{"type":"code-line","language":"python","children":[{"text":"# Save as a VTT file"}]},{"type":"code-line","language":"python","children":[{"text":"vtt_writer = get_writer(\"vtt\", output_directory)"}]},{"type":"code-line","language":"python","children":[{"text":"vtt_writer(result, audio)"}]}]},{"type":"heading","children":[{"text":"Bonus: Saving a Whisper transcription as a TSV or JSON file"}],"level":2},{"type":"paragraph","level":2,"children":[{"text":""},{"type":"link","url":"https://github.com/openai/whisper/commit/f5bfe004eccc3837a0d198baf7602ec7bccffafd","children":[{"text":"In late January 2023"}]},{"text":", OpenAI added the options to save transcripts as a TSV (tab-separated values) file! Like the other formats, simply use "},{"text":"get_writer()","inlineCode":true},{"text":" to call "},{"type":"link","url":"https://github.com/openai/whisper/blob/main/whisper/utils.py#L118","children":[{"text":"WriteTSV.write_result()","inlineCode":true}]},{"text":"."}]},{"type":"paragraph","level":2,"children":[{"text":"The resulting TSV file is separated into multiple segments, like the SRT and TSV files, and has three columns:"}]},{"type":"list","children":[{"type":"list-item","level":2,"children":[{"type":"paragraph","children":[{"text":"start","inlineCode":true},{"text":": The start time (in integer milliseconds) of the segment"}]}]},{"type":"list-item","level":2,"children":[{"type":"paragraph","children":[{"text":"end","inlineCode":true},{"text":": The start time (in integer milliseconds) of the segment"}]}]},{"type":"list-item","level":2,"children":[{"type":"paragraph","children":[{"text":"text","inlineCode":true},{"text":": The transcript of the segment"}]}]}]},{"type":"paragraph","children":[{"text":"Whisper also supports saving the transcript as a JSON file:"}]},{"type":"code-block","language":"python","children":[{"type":"code-line","language":"python","children":[{"text":"import whisper"}]},{"type":"code-line","language":"python","children":[{"text":"from whisper.utils import get_writer"}]},{"type":"code-line","language":"python","children":[{"text":""}]},{"type":"code-line","language":"python","children":[{"text":"model = whisper.load_model(\"base\")"}]},{"type":"code-line","language":"python","children":[{"text":"audio = \"audio.mp3\""}]},{"type":"code-line","language":"python","children":[{"text":"result = model.transcribe(audio)"}]},{"type":"code-line","language":"python","children":[{"text":"output_directory = \"./\""}]},{"type":"code-line","language":"python","children":[{"text":""}]},{"type":"code-line","language":"python","children":[{"text":"# Save as a TSV file"}]},{"type":"code-line","language":"python","children":[{"text":"tsv_writer = get_writer(\"tsv\", output_directory)"}]},{"type":"code-line","language":"python","children":[{"text":"tsv_writer(result, audio)"}]},{"type":"code-line","language":"python","children":[{"text":""}]},{"type":"code-line","language":"python","children":[{"text":"# Save as a JSON file"}]},{"type":"code-line","language":"python","children":[{"text":"json_writer = get_writer(\"json\", output_directory)"}]},{"type":"code-line","language":"python","children":[{"text":"json_writer(result, audio)"}]}]},{"type":"heading","children":[{"text":"Example Transcriptions"}],"level":2},{"type":"paragraph","children":[{"text":"Here are the results of running the "},{"text":"medium.en","inlineCode":true},{"text":" Whisper model \""},{"type":"link","url":"https://www.youtube.com/watch?v=wbonGgk-_Gk","children":[{"text":"Cristóbal Valenzuela — The Next Generation of Content Creation and AI"}]},{"text":"\", using the "},{"text":"medium.en","inlineCode":true},{"text":" model, saved in different formats:"}]},{"type":"list","children":[{"type":"list-item","children":[{"text":"As a text file "},{"type":"link","url":"https://drive.google.com/file/d/15XcT26XNf5BVJbZu1yoqNecffmk4_GlZ/view?usp=share_link","children":[{"text":"without line breaks"}]},{"text":""}]},{"type":"list-item","children":[{"text":"As a text file "},{"type":"link","url":"https://drive.google.com/file/d/1edw9AB8zYvD9Ep5rjyPjHx41Delh5MqN/view?usp=share_link","children":[{"text":"with line breaks"}]},{"text":""}]},{"type":"list-item","children":[{"text":"As an "},{"type":"link","url":"https://drive.google.com/file/d/1_yehInyCwXx-_NkCAxytX0DfWiJREJdt/view?usp=share_link","children":[{"text":"SRT file"}]},{"text":""}]},{"type":"list-item","children":[{"text":"As a "},{"type":"link","url":"https://drive.google.com/file/d/1xnjOrjlRpVsYdcweSBRHsPqhNP67rpIB/view?usp=share_link","children":[{"text":"VTT file"}]},{"text":""}]},{"type":"list-item","children":[{"text":"As a "},{"type":"link","url":"https://drive.google.com/file/d/1DKp_5krTqyVKixSXyhZ0zhkkuOz66tYj/view?usp=share_link","children":[{"text":"TSV file"}]},{"text":""}]},{"type":"list-item","children":[{"text":"As a"},{"type":"link","url":"https://drive.google.com/file/d/1hRlYU5wF0wmDisXKiMaqYTs4qXpci0HC/view?usp=share_link","children":[{"text":" JSON file"}]},{"text":""}]}]},{"type":"heading","children":[{"text":"How to Run Whisper On Google Colab"}],"level":1},{"type":"paragraph","children":[{"text":"So, how do you actually run Whisper on a real file? Since we’re using the Whisper Python library, we’ll need to set up either a local or a cloud-based Python environment like Google Colab. If you’re new to programming or machine learning, we strongly recommend using Whisper via Colab.  "}]},{"type":"paragraph","children":[{"text":"Installing Python and setting up the appropriate environments can be challenging, and Colab does pretty much all of the hard work for you 🙏"}]},{"type":"heading","children":[{"text":"What Is Google Colab?"}],"level":2},{"type":"paragraph","children":[{"text":"Google Colab (short for “Colaboratory”) is a Jupyter notebook and compute environment hosted by Google for free. You can write "},{"text":"and","emphasis":true},{"text":" execute Python code within a browser-based Colab notebook, without having to install your own Python development environment. "}]},{"type":"paragraph","children":[{"text":"Like Google Docs, Google Colab is cloud-based: Colab notebooks (also just called ”Colabs”) are stored in your Google Drive account, can be shared with a single link, can be edited by multiple people, and are accessible from anywhere. Colabs also allow you to combine executable code blocks with rich text and images, and create dynamic, interactive documents."}]},{"type":"paragraph","children":[{"text":"Colabs let you get started with writing and executing code immediately, and also provides access to "},{"type":"link","children":[{"text":"more powerful computing power"}],"url":"https://research.google.com/colaboratory/faq.html","title":null},{"text":" than you might otherwise be able to use — access to a GPU can make a huge difference in how long it takes Whisper to transcribe a file!"}]},{"type":"callout-block","children":[{"type":"callout-line","children":[{"text":"For more information about Google Colab, read Google’s \""},{"type":"link","url":"https://colab.research.google.com/","children":[{"text":"Welcome To Colaboratory"}]},{"text":"” and “"},{"type":"link","url":"https://colab.research.google.com/notebooks/basic_features_overview.ipynb","children":[{"text":"Overview of Colaboratory Features"}]},{"text":"\"."}]}]},{"type":"heading","children":[{"text":"The “Transcribe Audio With Whisper” Colab"}],"level":2},{"type":"paragraph","children":[{"text":"We’ve provided a Colab that contains all of the code you need to transcribe with Whisper! You can transcribe three types of files, with three different output formats:"}]},{"type":"list","children":[{"type":"list-item","children":[{"type":"paragraph","children":[{"text":"Possible inputs"}]},{"type":"list","children":[{"type":"list-item","children":[{"type":"paragraph","children":[{"text":"A YouTube video (the audio stream is downloaded via the provided URL, and then transcribed)"}]}],"checked":null,"spread":false,"ordered":false},{"type":"list-item","children":[{"type":"paragraph","children":[{"text":"A file in your Google Drive account"}]}],"checked":null,"spread":false,"ordered":false},{"type":"list-item","children":[{"type":"paragraph","children":[{"text":"A local file that you have uploaded to this Colab"}]}],"checked":null,"spread":false,"ordered":false}],"ordered":false,"start":null,"spread":false}],"checked":null,"spread":false,"ordered":false},{"type":"list-item","children":[{"type":"paragraph","children":[{"text":"Possible outputs"}]},{"type":"list","children":[{"type":"list-item","children":[{"type":"paragraph","children":[{"text":"A plain text file"}]}],"checked":null,"spread":false,"ordered":false},{"type":"list-item","children":[{"type":"paragraph","children":[{"text":"An SRT file"}]}],"checked":null,"spread":false,"ordered":false},{"type":"list-item","children":[{"type":"paragraph","children":[{"text":"A VTT file"}]}],"checked":null,"spread":false,"ordered":false},{"type":"list-item","children":[{"type":"paragraph","children":[{"text":"A TSV file"}]}],"checked":null,"spread":false,"ordered":false}],"ordered":false,"start":null,"spread":false}],"checked":null,"spread":false,"ordered":false}],"ordered":false,"start":null,"spread":false},{"type":"heading","children":[{"text":"Link to the Colab"}],"level":3},{"type":"paragraph","level":3,"children":[{"text":""}]},{"type":"image","url":"https://colab.research.google.com/assets/colab-badge.svg","title":null,"alt":"Open In Colab","children":[{"text":""}],"href":"https://colab.research.google.com/drive/1zEydNXx3OvbIf_IwfFkJN34ipwp3rgiQ?usp=sharing","width":435},{"type":"paragraph","level":2,"children":[{"emphasis":true,"text":""}]},{"type":"heading","children":[{"text":"Instructions for the Colab"}],"level":3},{"type":"list","children":[{"type":"list-item","children":[{"type":"paragraph","children":[{"emphasis":true,"text":"Optional"},{"text":": If you want to transcribe a local file, you will need to upload it to the Colab first. This step is not necessary if you are transcribing a YouTube video or a file in your Google Drive account."}]},{"type":"list","ordered":false,"children":[{"type":"list-item","children":[{"text":"Click the folder icon on the left menu to open the "},{"strong":true,"text":"Files"},{"text":" tab. Then, click the upload icon to upload your desired file. You can also drag and drop the file to upload it. This file will be deleted when the Colab runtime disconnects."}],"checked":null,"spread":false,"ordered":false}]},{"type":"image","children":[{"text":""}],"url":"https://api.wandb.ai/files/wandb_fc/images/projects/37068502/ff149043.png"}],"checked":null,"spread":false,"ordered":true},{"type":"list-item","children":[{"type":"paragraph","children":[{"text":"Change the values of the variables in the “🌴"},{"strong":true,"text":" Change the values in this section"},{"text":"” block:"}]},{"type":"image","url":"https://api.wandb.ai/files/wandb_fc/images/projects/37068502/88c28f44.png","title":null,"alt":"change values.png","children":[{"text":""}]}],"checked":null,"spread":true,"ordered":true},{"type":"list-item","children":[{"type":"paragraph","children":[{"text":"Click "},{"strong":true,"text":"Runtime"},{"text":" > "},{"strong":true,"text":"Run all"},{"text":". That's it!"}]},{"type":"image","children":[{"text":""}],"url":"https://api.wandb.ai/files/wandb_fc/images/projects/37068502/4b4bcfa6.png","width":662}],"checked":null,"spread":true,"ordered":true},{"type":"list-item","children":[{"type":"paragraph","children":[{"emphasis":true,"text":"Optional"},{"text":": Download your transcriptions."}]},{"type":"list","children":[{"type":"list-item","children":[{"type":"paragraph","children":[{"text":"If you set "},{"inlineCode":true,"text":"download = True"},{"text":", then this Colab will automatically download the specified transcription/caption files. However, if you forgot to do this, you can also download the transcribed file(s) afterwards! Just make sure to download the files before you disconnect the Colab, since they will be deleted along with the runtime."}]}],"checked":null,"spread":false,"ordered":false},{"type":"list-item","children":[{"type":"paragraph","children":[{"text":"As in Step 1, click the folder icon to open the "},{"strong":true,"text":"Files"},{"text":" tab. Then, click the kebab menu icon to the right of the desired file, and select "},{"strong":true,"text":"Download"},{"text":"."}]}],"checked":null,"spread":false,"ordered":false}],"ordered":false,"start":null,"spread":false}],"checked":null,"spread":false,"ordered":true}],"ordered":true,"start":1,"spread":false},{"type":"heading","children":[{"text":"Summary"}],"level":1},{"type":"paragraph","children":[{"text":"Congratulations on completing the tutorial! 🥳"}]},{"type":"paragraph","children":[{"text":"In this article, we learned how to use Whisper to transcribe audio, and save that transcription as a text file or as an SRT/VTT file."}]},{"type":"heading","children":[{"text":"Tracking and Comparing Whisper Transcriptions"}],"level":2},{"type":"paragraph","children":[{"text":"You might now be wondering how different Whisper models compare to each other — this article and Colab used the medium-sized, English-only model, but there are both bigger and smaller models."}]},{"type":"paragraph","children":[{"text":"In the next article, we’ll dive into how to compare "},{"strong":true,"text":"and track"},{"text":" the results of different Whisper models using Weights & Biases, a collection of tools for machine learning projects and workflows."}]},{"type":"paragraph","children":[{"text":"Thanks for reading and stay tuned!"}]},{"type":"paragraph","level":2,"children":[{"text":"A note from the author:","emphasis":true,"strong":true},{"emphasis":true,"text":" Hi, I'm Angelica, a technical writer at "},{"type":"link","url":"https://wandb.ai/site?utm_source=fully_connected&utm_medium=blog&utm_campaign=gentle-intro-models","children":[{"emphasis":true,"text":"Weights & Biases"}]},{"emphasis":true,"text":" — we make tools for machine learning. If you enjoyed this article, consider following us on "},{"type":"link","url":"https://twitter.com/metaphdor?utm_source=fully_connected&utm_medium=blog&utm_campaign=gentle-intro-models","children":[{"text":"Twitter","emphasis":true}]},{"text":" or ","emphasis":true},{"type":"link","url":"https://www.youtube.com/c/WeightsBiases?utm_source=fully_connected&utm_medium=blog&utm_campaign=gentle-intro-models","children":[{"text":"YouTube","emphasis":true}]},{"text":" :)","emphasis":true}]},{"type":"heading","level":2,"children":[{"text":"Related Reading"}]},{"type":"paragraph","level":2,"children":[{"text":"If you enjoyed learning about Whisper, you might also enjoy this article on fine-tuning Whisper:"}]},{"type":"gallery","level":2,"children":[{"text":""}],"links":[{"type":"report","id":"VmlldzozMTYyNTg0"}]},{"type":"paragraph","children":[{"text":""}]}],"width":"readable","authors":[{"username":"angelicapan","name":"Angelica Pan"}],"discussionThreads":[{"id":"RGlzY3Vzc2lvblRocmVhZDo2MzE0","poster":{"id":"VXNlcjo2MTk4MTE=","username":"romanvinogradovby","name":"Roman Vinogradov","photoUrl":"https://lh3.googleusercontent.com/a/AGNmyxbXN_qPRd_NlvScNxps3DJ9ucK0LbdBDbnAkmPR=s96-c","admin":false},"createdAt":"2023-05-03T08:30:22","comments":[{"id":"RGlzY3Vzc2lvbkNvbW1lbnQ6ODk5Mg==","body":"Can't debug it even with the help of ChatGPT.","poster":{"id":"VXNlcjo2MTk4MTE=","username":"romanvinogradovby","name":"Roman Vinogradov","photoUrl":"https://lh3.googleusercontent.com/a/AGNmyxbXN_qPRd_NlvScNxps3DJ9ucK0LbdBDbnAkmPR=s96-c","admin":false},"createdAt":"2023-05-03T08:30:22","ref":{"type":"discussion-comment","viewID":"oiz1vael7","id":"prmbuxo3d"}}],"ref":{"type":"discussion-thread","viewID":"oiz1vael7","id":"lz4dird64"}},{"id":"RGlzY3Vzc2lvblRocmVhZDo2MzEz","poster":{"id":"VXNlcjo2MTk4MTE=","username":"romanvinogradovby","name":"Roman Vinogradov","photoUrl":"https://lh3.googleusercontent.com/a/AGNmyxbXN_qPRd_NlvScNxps3DJ9ucK0LbdBDbnAkmPR=s96-c","admin":false},"createdAt":"2023-05-03T08:29:32","comments":[{"id":"RGlzY3Vzc2lvbkNvbW1lbnQ6ODk5MQ==","body":"NameError: name 'audio' is not defined","poster":{"id":"VXNlcjo2MTk4MTE=","username":"romanvinogradovby","name":"Roman Vinogradov","photoUrl":"https://lh3.googleusercontent.com/a/AGNmyxbXN_qPRd_NlvScNxps3DJ9ucK0LbdBDbnAkmPR=s96-c","admin":false},"createdAt":"2023-05-03T08:29:32","ref":{"type":"discussion-comment","viewID":"oiz1vael7","id":"5ed54afr4"}}],"ref":{"type":"discussion-thread","viewID":"oiz1vael7","id":"xspkcvwuj"}},{"id":"RGlzY3Vzc2lvblRocmVhZDo2Mjc2","poster":{"id":"VXNlcjo2MTU4OTQ=","username":"captainfortissimo","name":"Anthony G","photoUrl":"https://avatars.githubusercontent.com/u/132007197?v=4","admin":false},"createdAt":"2023-04-27T18:58:19","comments":[{"id":"RGlzY3Vzc2lvbkNvbW1lbnQ6ODkyOQ==","body":"Thank you so much for this tutorial!  I appreciate the easy to follow steps.  However, I have been unable to successfully run this in Google Collab.  I'm trying to transcribe a file in my google drive.  I input the appropriate options (selected \"gdrive\" for the path and used the appropriate path to the file) and select the plain, srt, vtt, and download options.  \n\nAfter clicking \"run all\", everything works well until the final step (\"Whisper It!\")  After processing the source file, I get the following error:\n\nResultWriter.__call__() missing 1 required positional argument: 'options'\n\nThe error seems to be on this line in the final block of code:\n\n# Run Whisper on the specified file\n    result = transcribe_file(model, file, plain, srt, vtt, tsv, download)\n\nDo you know what the issue could be?  I have changed nothing else in the provided workbook.  Thank you again!","poster":{"id":"VXNlcjo2MTU4OTQ=","username":"captainfortissimo","name":"Anthony G","photoUrl":"https://avatars.githubusercontent.com/u/132007197?v=4","admin":false},"createdAt":"2023-04-27T18:58:19","ref":{"type":"discussion-comment","viewID":"oiz1vael7","id":"gcstskow0"}},{"id":"RGlzY3Vzc2lvbkNvbW1lbnQ6ODkzMA==","body":"Just to add to this... It looks like the plain text file outputting, but it hits the error when it tries to export the srt or vtt files.","poster":{"id":"VXNlcjo2MTU4OTQ=","username":"captainfortissimo","name":"Anthony G","photoUrl":"https://avatars.githubusercontent.com/u/132007197?v=4","admin":false},"createdAt":"2023-04-27T19:00:01","ref":{"type":"discussion-comment","viewID":"oiz1vael7","id":"v7g4n9f13"}},{"id":"RGlzY3Vzc2lvbkNvbW1lbnQ6OTA1NQ==","body":"same probelms, looks like whisper changed how the get_writer() function works. Don't know how to fix it :(","poster":{"id":"VXNlcjo2MjcxNzk=","username":"crawfish","name":"crawfish","photoUrl":"https://s.gravatar.com/avatar/9619fee98050c978321089fc20893199?s=480&r=pg&d=https%3A%2F%2Fcdn.auth0.com%2Favatars%2Fzf.png","admin":false},"createdAt":"2023-05-10T23:10:23","ref":{"type":"discussion-comment","viewID":"oiz1vael7","id":"6bm4exizp"}},{"id":"RGlzY3Vzc2lvbkNvbW1lbnQ6OTQ0Nw==","body":"Hey!  Not sure if you're still having this issue.  It ended up being that you have to use a different version of whisper.  I believe it was the nightly builds or something like that.  I used a different code than what's on this site, but the crux was !pip install openai-whisper","poster":{"id":"VXNlcjo2MTU4OTQ=","username":"captainfortissimo","name":"Anthony G","photoUrl":"https://avatars.githubusercontent.com/u/132007197?v=4","admin":false},"createdAt":"2023-06-26T14:26:48","ref":{"type":"discussion-comment","viewID":"oiz1vael7","id":"qflc88dte"}}],"ref":{"type":"discussion-thread","viewID":"oiz1vael7","id":"gcuu4jb0s"}},{"id":"RGlzY3Vzc2lvblRocmVhZDo1ODk3","poster":{"id":"VXNlcjo1NzQzNjk=","username":"joevega0017","name":"Jhon Richard","photoUrl":"https://lh3.googleusercontent.com/a/AGNmyxZoQtqtBnSGHpnVYM-Zt4U_9ts6fCw37-Ot5Ew6=s96-c","admin":false},"createdAt":"2023-03-13T12:12:00","comments":[{"id":"RGlzY3Vzc2lvbkNvbW1lbnQ6ODQzMw==","body":"Possible to update the code for a bulk transcription.\n\nThanks","poster":{"id":"VXNlcjo1NzQzNjk=","username":"joevega0017","name":"Jhon Richard","photoUrl":"https://lh3.googleusercontent.com/a/AGNmyxZoQtqtBnSGHpnVYM-Zt4U_9ts6fCw37-Ot5Ew6=s96-c","admin":false},"createdAt":"2023-03-13T12:12:00","ref":{"type":"discussion-comment","viewID":"oiz1vael7","id":"6320dn6lq"}}],"ref":{"type":"discussion-thread","viewID":"oiz1vael7","id":"4n4ref0c9"}},{"id":"RGlzY3Vzc2lvblRocmVhZDo1NTIx","poster":{"id":"VXNlcjo4NzM4Mg==","username":"angelicapan","name":"Angelica Pan","photoUrl":"https://storage.googleapis.com/wandb-production.appspot.com/angelicapan/profile.png?Expires=1688130241&GoogleAccessId=wandb-production%40appspot.gserviceaccount.com&Signature=WnABcTDaerXbi1G6WCaAQHBz19nzRNW%2BQSwhrzydn2hM1M%2BeLOEMMSMdjbBtq0%2FWZs%2BehqSMivxlqk2GbFVtv8RPfumF4V2yMji%2Fo%2FJdvtjVKqspcdE%2FihT1oQy6if5iJis%2BVOT9WzURDmFvwKs%2BczUakI60OmSnXj7LWHZivtdakZLnrtmLoZp4rXFkp9Y7T8h341bZ3AzjEcfVz8kzdKX4EKO621yaZNnqrUpqOVAjWuGGJBkrabIJ5%2FbX3%2Fp%2BDrgxBIQ9FyGSTOa5%2B4qc7iXpIZKUTHtuqbTOFRv9v0w448BphaB2nqlenLMmu6xz%2BYCbC8Goc%2FrnqFVEhO6pvg%3D%3D","admin":false},"createdAt":"2023-02-03T23:21:05","comments":[{"id":"RGlzY3Vzc2lvbkNvbW1lbnQ6Nzk3MA==","body":"|[multilingual](yji60gzp1) Since Whisper was trained on multilingual audio, its capabilities actually extend far beyond transcribing speech-to-text in English! \n\nWhisper is capable of:\n- English transcription\n- Non-English foreign language to English translation\n- Non-English foreign language transcription\n\nFor this article, however, we’ll focus on English transcription only.","poster":{"id":"VXNlcjo4NzM4Mg==","username":"angelicapan","name":"Angelica Pan","photoUrl":"https://storage.googleapis.com/wandb-production.appspot.com/angelicapan/profile.png?Expires=1688130241&GoogleAccessId=wandb-production%40appspot.gserviceaccount.com&Signature=WnABcTDaerXbi1G6WCaAQHBz19nzRNW%2BQSwhrzydn2hM1M%2BeLOEMMSMdjbBtq0%2FWZs%2BehqSMivxlqk2GbFVtv8RPfumF4V2yMji%2Fo%2FJdvtjVKqspcdE%2FihT1oQy6if5iJis%2BVOT9WzURDmFvwKs%2BczUakI60OmSnXj7LWHZivtdakZLnrtmLoZp4rXFkp9Y7T8h341bZ3AzjEcfVz8kzdKX4EKO621yaZNnqrUpqOVAjWuGGJBkrabIJ5%2FbX3%2Fp%2BDrgxBIQ9FyGSTOa5%2B4qc7iXpIZKUTHtuqbTOFRv9v0w448BphaB2nqlenLMmu6xz%2BYCbC8Goc%2FrnqFVEhO6pvg%3D%3D","admin":false},"createdAt":"2023-02-03T23:21:05","ref":{"type":"discussion-comment","viewID":"oiz1vael7","id":"njokm7nf9"}}],"ref":{"type":"discussion-thread","viewID":"oiz1vael7","id":"e52o3spcc"}}],"ref":{"type":"runs/draft","viewID":"oiz1vael7","id":"qk4xifeei"}}}